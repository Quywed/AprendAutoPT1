{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39c6c357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "# Importar modelos\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378a02fe-3f59-4c3a-a36c-aa3e7bf775b0",
   "metadata": {},
   "source": [
    "<center><img src=\"ml_lfcl.png\"></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99a74b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "# Importar modelos\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b236f0-7956-457c-870e-8f7f60b6af70",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Data collection, Data Cleaning & Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370b887a-4473-44e1-9d38-72dbab3d2a1c",
   "metadata": {},
   "source": [
    "### Método de **Feature Engeneering** e **Limpeza de Dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0d1cd4c-c1f5-45be-8b21-f35b190fdc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engeneering(df):\n",
    "    df_eng = df.copy()\n",
    "\n",
    "    # --- LIMPEZA INICIAL ---\n",
    "    df_eng = df_eng.drop_duplicates()\n",
    "    df_eng['hp'] = df['engine'].str.extract(r'(\\d+\\.?\\d*)HP', expand=False).astype(float)\n",
    "    df_eng['liters'] = df['engine'].str.extract(r'(\\d+\\.?\\d*)L\\s', expand=False).astype(float)\n",
    "\n",
    "    # --- Idade e Uso ---\n",
    "    var_ano_atual = date.today().year\n",
    "    df_eng['car_age'] = var_ano_atual - df_eng['model_year']\n",
    "    df_eng['car_age'] = df_eng['car_age'].replace(0, 1)\n",
    "\n",
    "    # --- Cilindrada ---\n",
    "    df_eng['cylinders'] = df['engine'].str.extract(r'(\\d+)\\s+Cylinder', expand=False)\n",
    "    df_eng['cylinders'] = df_eng['cylinders'].fillna(df['engine'].str.extract(r'V(\\d+)', expand=False))\n",
    "    df_eng['cylinders'] = df_eng['cylinders'].astype(float)\n",
    "\n",
    "    # --- Tecnologias de Motor ---\n",
    "    df_eng['is_turbo'] = df['engine'].str.contains(r'(?i)turbo', na=False).astype(int)\n",
    "    df_eng['turbo_type'] = df['engine'].str.extract(r'(Twin Turbo|Turbo)', expand=False)\n",
    "    df_eng['valve_train'] = df['engine'].str.extract(r'(DOHC|OHV|SOHC)', expand=False) \n",
    "    df_eng['fuel_injection'] = df['engine'].str.extract(r'(PDI|GDI|MPFI)', expand=False)\n",
    "\n",
    "    # Miles per year\n",
    "    df_eng['miles_p_year'] = df_eng['milage'] / df_eng['car_age']\n",
    "\n",
    "    # --- FUEL TYPE ---\n",
    "    def clean_fuel(val):\n",
    "        s = str(val).lower()\n",
    "        if 'hybrid' in s:\n",
    "            return 'Hybrid'\n",
    "        elif 'not supported' in s:\n",
    "            return 'EV'\n",
    "        else:\n",
    "            return val\n",
    "    df_eng['fuel_type'] = df_eng['fuel_type'].apply(clean_fuel)\n",
    "\n",
    "    # --- TRANSMISSION TYPE ---\n",
    "    def clean_transmission(val):\n",
    "        s = str(val).lower()\n",
    "        if 'automatic' in s or 'a/t' in s or 'cvt' in s:\n",
    "            return 'Automatico'\n",
    "        elif 'manual' in s or 'm/t' in s:\n",
    "            return 'Manual'\n",
    "        else:\n",
    "            return 'Outro'\n",
    "    df_eng['transmission_type'] = df_eng['transmission'].apply(clean_transmission)\n",
    "\n",
    "    # --- Cores ---\n",
    "    top_ext_colors = df_eng['ext_col'].value_counts().nlargest(10).index\n",
    "    def simplificar_cor_ext(cor):\n",
    "        return cor if cor in top_ext_colors else 'Other'\n",
    "    df_eng['ext_col_simple'] = df_eng['ext_col'].apply(simplificar_cor_ext)\n",
    "\n",
    "    top_int_colors = df_eng['int_col'].value_counts().nlargest(10).index\n",
    "    def simplificar_cor_int(cor):\n",
    "        return cor if cor in top_int_colors else 'Other'\n",
    "    df_eng['int_col_simple'] = df_eng['int_col'].apply(simplificar_cor_int)\n",
    "\n",
    "    # --- Tratamento de Nulos ---\n",
    "    cols_texto = df_eng.select_dtypes(include=['object']).columns\n",
    "    df_eng[cols_texto] = df_eng[cols_texto].replace('-', 'Unknown').fillna('Unknown')\n",
    "    df_eng['clean_title'] = df_eng['clean_title'].replace('Unknown', 'No')\n",
    "\n",
    "    # --- Acidente ---\n",
    "    def verificar_acidente(valor):\n",
    "        return 0 if 'None' in str(valor) else 1\n",
    "    df_eng['accident_clean'] = df_eng['accident'].apply(verificar_acidente)\n",
    "\n",
    "    # 1. Eficiência do motor\n",
    "    # Evitar divisão por zero somando um valor ínfimo\n",
    "    df_eng['hp_per_liter'] = df_eng['hp'] / (df_eng['liters'] + 0.001)\n",
    "\n",
    "    # 2. Rácio de Potência por Cilindro\n",
    "    df_eng['hp_per_cylinder'] = df_eng['hp'] / (df_eng['cylinders'] + 0.001)\n",
    "\n",
    "    # 3. Quilometragem (Milage)\n",
    "    # A milage tem uma distribuição muito \"cauda longa\". O Log ajuda o modelo a ver melhor as diferenças.\n",
    "    df_eng['milage_log'] = np.log1p(df_eng['milage'])\n",
    "\n",
    "    return df_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "280497d8-29a5-47f9-b409-0ab6895180a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dados lidos com Sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Recolha os Dados\n",
    "df_treino = pd.read_csv('dados/train.csv', index_col='id')\n",
    "df_teste = pd.read_csv('dados/test.csv', index_col='id')\n",
    "\n",
    "print(\"✓ Dados lidos com Sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ca2d9e5-8239-44e4-b8d2-9e353cc7ffe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Feature Engineering Aplicado com Sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Aplicar feature engineering e Limpeza de dados\n",
    "df_treino_eng = feature_engeneering(df_treino)\n",
    "df_teste_eng = feature_engeneering(df_teste)\n",
    "\n",
    "print(\"✓ Feature Engineering Aplicado com Sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21f97aa2-446c-4858-b182-826690dfe566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique brands:['MINI' 'Lincoln' 'Chevrolet' 'Genesis' 'Mercedes-Benz' 'Audi' 'Ford'\n",
      " 'BMW' 'Tesla' 'Cadillac' 'Land' 'GMC' 'Toyota' 'Hyundai' 'Volvo'\n",
      " 'Volkswagen' 'Buick' 'Rivian' 'RAM' 'Hummer' 'Alfa' 'INFINITI' 'Jeep'\n",
      " 'Porsche' 'McLaren' 'Honda' 'Lexus' 'Dodge' 'Nissan' 'Jaguar' 'Acura'\n",
      " 'Kia' 'Mitsubishi' 'Rolls-Royce' 'Maserati' 'Pontiac' 'Saturn' 'Bentley'\n",
      " 'Mazda' 'Subaru' 'Ferrari' 'Aston' 'Lamborghini' 'Chrysler' 'Lucid'\n",
      " 'Lotus' 'Scion' 'smart' 'Karma' 'Plymouth' 'Suzuki' 'FIAT' 'Saab'\n",
      " 'Bugatti' 'Mercury' 'Polestar' 'Maybach']\n",
      "Nr:57\n"
     ]
    }
   ],
   "source": [
    "unique_names = df_treino_eng['brand'].unique()\n",
    "print(f\"Unique brands:{unique_names}\")\n",
    "print(f\"Nr:{unique_names.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9257153b-7949-495e-937c-a906c1e36dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar target\n",
    "y = np.log1p(df_treino_eng['price'])\n",
    "X = df_treino_eng\n",
    "X_test = df_teste_eng.copy()\n",
    "\n",
    "# Tipos de Features Relevantes para Previsao\n",
    "features_numericas = ['hp', 'liters', 'car_age', 'cylinders', 'miles_p_year','milage', 'model_year', 'is_turbo']\n",
    "\n",
    "features_categoricas = ['brand', 'model', 'fuel_type', 'transmission_type', \n",
    "                           'ext_col_simple', 'int_col_simple', 'clean_title', \n",
    "                           'turbo_type', 'valve_train', 'fuel_injection']\n",
    "\n",
    "# Criar dataset numérico\n",
    "X_num = X[features_numericas].fillna(0)\n",
    "X_test_num = X_test[features_numericas].fillna(0)\n",
    "\n",
    "# Encondificar features categoricas | (Ordinal Enconding) Transform each category into a number\n",
    "X_cat = X[features_categoricas].copy()\n",
    "X_test_cat = X_test[features_categoricas].copy()\n",
    "\n",
    "for col in features_categoricas:\n",
    "    le = LabelEncoder()\n",
    "    # Fit no treino\n",
    "    X_cat[col] = X_cat[col].astype(str)\n",
    "    le.fit(X_cat[col])\n",
    "    X_cat[col] = le.transform(X_cat[col])\n",
    "\n",
    "    # Transform no teste (tratando categorias novas)\n",
    "    X_test_cat[col] = X_test_cat[col].astype(str)\n",
    "    X_test_cat[col] = X_test_cat[col].apply(\n",
    "        lambda x: le.transform([x])[0] if x in le.classes_ else -1\n",
    "    )\n",
    "\n",
    "# Concatenar features\n",
    "X_final = pd.concat([X_num, X_cat], axis=1)\n",
    "X_test_final = pd.concat([X_test_num, X_test_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29c3e8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hp</th>\n",
       "      <th>liters</th>\n",
       "      <th>car_age</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>miles_p_year</th>\n",
       "      <th>milage</th>\n",
       "      <th>model_year</th>\n",
       "      <th>is_turbo</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>transmission_type</th>\n",
       "      <th>ext_col_simple</th>\n",
       "      <th>int_col_simple</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>turbo_type</th>\n",
       "      <th>valve_train</th>\n",
       "      <th>fuel_injection</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>172.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11210.526316</td>\n",
       "      <td>213000</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>495</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>252.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>24</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5968.750000</td>\n",
       "      <td>143250</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>930</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>320.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>24</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5697.125000</td>\n",
       "      <td>136731</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1575</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>420.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2166.666667</td>\n",
       "      <td>19500</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>758</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>208.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1477.600000</td>\n",
       "      <td>7388</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>1077</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       hp  liters  car_age  cylinders  miles_p_year  milage  model_year  \\\n",
       "id                                                                        \n",
       "0   172.0     1.6       19        4.0  11210.526316  213000        2007   \n",
       "1   252.0     3.9       24        8.0   5968.750000  143250        2002   \n",
       "2   320.0     5.3       24        8.0   5697.125000  136731        2002   \n",
       "3   420.0     5.0        9        8.0   2166.666667   19500        2017   \n",
       "4   208.0     2.0        5        4.0   1477.600000    7388        2021   \n",
       "\n",
       "    is_turbo  brand  model  fuel_type  transmission_type  ext_col_simple  \\\n",
       "id                                                                         \n",
       "0          0     31    495          3                  0               7   \n",
       "1          0     28    930          3                  0               9   \n",
       "2          0      9   1575          1                  0               1   \n",
       "3          0     16    758          3                  2               0   \n",
       "4          0     36   1077          3                  0               0   \n",
       "\n",
       "    int_col_simple  clean_title  turbo_type  valve_train  fuel_injection  \n",
       "id                                                                        \n",
       "0                4            1           2            3               3  \n",
       "1                0            1           2            3               3  \n",
       "2                4            1           2            3               3  \n",
       "3                1            1           2            3               3  \n",
       "4                0            1           2            3               3  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "add6e7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hp</th>\n",
       "      <th>liters</th>\n",
       "      <th>car_age</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>miles_p_year</th>\n",
       "      <th>milage</th>\n",
       "      <th>model_year</th>\n",
       "      <th>is_turbo</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>transmission_type</th>\n",
       "      <th>ext_col_simple</th>\n",
       "      <th>int_col_simple</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>turbo_type</th>\n",
       "      <th>valve_train</th>\n",
       "      <th>fuel_injection</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188533</th>\n",
       "      <td>240.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8909.090909</td>\n",
       "      <td>98000</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1390</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188534</th>\n",
       "      <td>395.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1523.666667</td>\n",
       "      <td>9142</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1377</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188535</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7030.250000</td>\n",
       "      <td>28121</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>636</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188536</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6125.800000</td>\n",
       "      <td>61258</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>182</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188537</th>\n",
       "      <td>252.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7375.000000</td>\n",
       "      <td>59000</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>181</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           hp  liters  car_age  cylinders  miles_p_year  milage  model_year  \\\n",
       "id                                                                            \n",
       "188533  240.0     2.0       11        4.0   8909.090909   98000        2015   \n",
       "188534  395.0     3.0        6        6.0   1523.666667    9142        2020   \n",
       "188535    0.0     3.5        4        6.0   7030.250000   28121        2022   \n",
       "188536    0.0     0.0       10        0.0   6125.800000   61258        2016   \n",
       "188537  252.0     2.0        8        4.0   7375.000000   59000        2018   \n",
       "\n",
       "        is_turbo  brand  model  fuel_type  transmission_type  ext_col_simple  \\\n",
       "id                                                                             \n",
       "188533         0     26   1390          3                  0              10   \n",
       "188534         0     26   1377          4                  0               9   \n",
       "188535         1     14    636          3                  0              10   \n",
       "188536         0      3    182          3                  0               7   \n",
       "188537         0      3    181          3                  0               4   \n",
       "\n",
       "        int_col_simple  clean_title  turbo_type  valve_train  fuel_injection  \n",
       "id                                                                            \n",
       "188533               0            1           2            3               3  \n",
       "188534               1            1           2            3               3  \n",
       "188535               3            0           1            0               2  \n",
       "188536               1            0           2            3               3  \n",
       "188537               1            1           2            3               3  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_final.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63acd19-160c-4d5d-b1d0-8d4c1380d278",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba937929-4fe3-4c86-8773-39807c953b9f",
   "metadata": {},
   "source": [
    "### Método de **Definição dos Modelos** - Dicionário com objetos dos modelos de previsão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e904fa6-c865-448f-8cbc-17a12aec33a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_modelos():\n",
    "    modelos = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "\n",
    "        'KNN': KNeighborsRegressor(),\n",
    "\n",
    "        'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "\n",
    "        'Random Forest': RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "\n",
    "        'XGBoost': xgb.XGBRegressor(random_state=42, n_jobs=-1),\n",
    "\n",
    "        'SVR Linear': SVR(kernel='linear'),\n",
    "\n",
    "        'MLP Small': MLPRegressor(random_state=42, early_stopping=True),\n",
    "    }\n",
    "\n",
    "    return modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e8ba8c-3cf5-4d78-bffd-e31391b1694b",
   "metadata": {},
   "source": [
    "### Métodos para **\"GridSearchCV\"** - Otimização de Hipérparametrso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2914ee7b-e49f-4982-b493-03a1eb05925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_params_grid(nome_modelo):\n",
    "    grids = {\n",
    "        'Linear Regression': {\n",
    "            'fit_intercept': [True, False],\n",
    "            'positive': [True, False]\n",
    "        },\n",
    "        'KNN': {\n",
    "            'n_neighbors': [3, 5, 7, 11],\n",
    "            'weights': ['uniform', 'distance'],\n",
    "            'p': [1, 2] # 1=Manhattan, 2=Euclidean\n",
    "        },\n",
    "        'Decision Tree': {\n",
    "            'max_depth': [5, 10, 20, None],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'criterion': ['squared_error', 'absolute_error']\n",
    "        },\n",
    "        'Random Forest': {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [10, 20, None],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        },\n",
    "        'XGBoost': {\n",
    "            'n_estimators': [100, 500, 1000],\n",
    "            'learning_rate': [0.01, 0.05, 0.1],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'subsample': [0.7, 0.9, 1.0],\n",
    "            'colsample_bytree': [0.7, 0.9, 1.0]\n",
    "        },\n",
    "        'SVR Linear': {\n",
    "            'C': [0.1, 1, 10, 100],\n",
    "            'epsilon': [0.01, 0.1, 0.5]\n",
    "        },\n",
    "        'MLP Small': {\n",
    "            'hidden_layer_sizes': [(50,50,50), (100,50), (100,)],\n",
    "            'activation': ['tanh', 'relu'],\n",
    "            'alpha': [0.0001, 0.05],\n",
    "        }\n",
    "    }\n",
    "    return grids.get(nome_modelo, {})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aebd0b0-48e9-41db-9f22-e9f2506c3a9e",
   "metadata": {},
   "source": [
    "A **Otimização de Hiperparâmetros, ou Hyperparameter Tuning em ingles**, é o processo de encontrar as melhores configurações para um modelo de Machine Learning, ajustando-as sistematicamente para otimizar o seu desempenho, precisão e capacidade de generalização. Os hiperparâmetros são definidos externamente antes da aprendizagem começar, servindo como o \"manual de instruções\" que molda o comportamento do algoritmo.\n",
    "\n",
    "Para cada modelo, é definida uma grelha de valores para os hiperparâmetros pretendidos e, posteriormente, com a ajuda de Cross Validation (Validação Cruzada), o modelo é testado em diferentes subconjuntos de dados. No caso do GridSearchCV, o sistema executa uma pesquisa exaustiva, realizando todas as combinações possíveis da grelha para identificar qual delas maximiza uma métrica de desempenho específica, neste caso o RMSE (Root Mean Squared Error)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b695396-e4ba-428c-8782-6d00729b9177",
   "metadata": {},
   "source": [
    "### Explicação dos Hiperparâmetros por Modelo\n",
    "\n",
    "#### 1. Regressão Linear (Linear Regression)\n",
    "A Regressão Linear tenta encontrar a melhor linha reta que minimiza a diferença quadrática entre os valores reais e as previsões.\n",
    "\n",
    "* **`fit_intercept` [True, False]**:\n",
    "    * **Porquê estes valores?** Determina se o modelo deve calcular o ponto onde a reta cruza o eixo Y. Na quase totalidade dos casos práticos, os dados não passam pela origem $(0,0)$, pelo que `True` é o padrão. Testa-se `False` apenas se os dados já tiverem sido centralizados.\n",
    "    * **Como se encaixa:** Controla a flexibilidade vertical da reta de regressão.\n",
    "\n",
    "* **`positive` [True, False]**:\n",
    "    * **Porquê estes valores?** Força todos os coeficientes a serem maiores ou iguais a zero.\n",
    "    * **Como se encaixa:** É uma restrição física ou de negócio. Se soubermos que as variáveis independentes apenas podem contribuir positivamente para o resultado, ativar esta opção evita coeficientes negativos espúrios causados por ruído.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. KNN (K-Nearest Neighbors)\n",
    "O KNN baseia as suas previsões na média dos valores dos $K$ pontos mais próximos no espaço de características.\n",
    "\n",
    "* **`n_neighbors` [3, 5, 7, 11]**:\n",
    "    * **Porquê estes valores?** Valores ímpares são usados para evitar empates. Começamos com um valor baixo (3) para capturar padrões locais e subimos até 11 para suavizar a previsão e reduzir a sensibilidade a *outliers*.\n",
    "    * **Como se encaixa:** Controla o equilíbrio entre viés e variância. $K$ pequeno pode levar a *overfitting*; $K$ grande pode levar a *underfitting*.\n",
    "\n",
    "* **`weights` ['uniform', 'distance']**:\n",
    "    * **Porquê estes valores?** 'Uniform' dá o mesmo peso a todos os vizinhos. 'Distance' dá mais importância aos vizinhos que estão realmente mais perto.\n",
    "    * **Como se encaixa:** Permite que o modelo seja mais refinado, dando mais \"voto\" a quem está geograficamente mais próximo do ponto a prever.\n",
    "\n",
    "* **`p` [1, 2]**:\n",
    "    * **Como se encaixa:** Define a métrica de distância. $p=1$ é a distância de Manhattan (movimentos em grelha); $p=2$ é a Euclidiana (distância em linha reta). A escolha depende da escala e da relação entre as variáveis.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Árvore de Decisão (Decision Tree)\n",
    "Divide os dados em ramificações baseadas em regras lógicas de \"maior que\" ou \"menor que\".\n",
    "\n",
    "* **`max_depth` [5, 10, 20, None]**:\n",
    "    * **Porquê estes valores?** Limitamos a profundidade para evitar que a árvore cresça infinitamente e decore o ruído dos dados. `None` permite o crescimento total, servindo como ponto de comparação.\n",
    "    * **Como se encaixa:** É o principal controlador de complexidade. Árvores muito profundas são propensas a *overfitting*.\n",
    "\n",
    "* **`min_samples_split` [2, 5, 10]** e **`min_samples_leaf` [1, 2, 4]**:\n",
    "    * **Porquê estes valores?** Impedem a criação de nós ou folhas com pouquíssimas amostras. \n",
    "    * **Como se encaixa:** Funcionam como regularizadores. Forçam a árvore a basear as suas decisões em grupos de dados estatisticamente mais significativos.\n",
    "\n",
    "* **`criterion` ['squared_error', 'absolute_error']**:\n",
    "    * **Como se encaixa:** Define a função de perda. O `squared_error` foca-se na média, enquanto o `absolute_error` foca-se na mediana, sendo este último muito mais robusto contra dados que contenham valores aberrantes (*outliers*).\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Random Forest\n",
    "Um modelo de *ensemble* que cria centenas de árvores independentes e faz a média dos seus resultados.\n",
    "\n",
    "* **`n_estimators` [100, 200, 300]**:\n",
    "    * **Porquê estes valores?** 100 é a base recomendada. Aumentar para 300 ajuda a estabilizar a variância do modelo, embora aumente o tempo de treino.\n",
    "    * **Como se encaixa:** Mais árvores geralmente significam um modelo mais robusto, até se atingir um ponto de retorno decrescente onde o tempo de processamento não compensa o ganho de precisão.\n",
    "\n",
    "* **Parâmetros de Árvore (`max_depth`, etc.)**:\n",
    "    * Seguem a mesma lógica da Árvore de Decisão, mas como o Random Forest usa amostragem aleatória, podemos permitir árvores ligeiramente mais complexas do que no modelo individual.\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. XGBoost\n",
    "Um modelo de *Gradient Boosting* onde as árvores são construídas sequencialmente para corrigir os erros das anteriores.\n",
    "\n",
    "* **`learning_rate` [0.01, 0.05, 0.1]**:\n",
    "    * **Como se encaixa:** Controla o impacto de cada nova árvore. Um valor baixo (0.01) significa que o modelo aprende lentamente, o que requer mais árvores mas resulta numa generalização muito superior.\n",
    "* **`n_estimators` [100, 500, 1000]**:\n",
    "    * **Porquê estes valores?** Como as árvores no XGBoost são \"aprendizes fracos\", precisamos de muitas iterações (especialmente com um `learning_rate` baixo) para convergir para uma boa solução.\n",
    "* **`subsample`** e **`colsample_bytree` [0.7, 0.9, 1.0]**:\n",
    "    * **Como se encaixa:** Introduzem aleatoriedade ao usar apenas uma fração dos dados ou das colunas em cada passo. Isto impede que o modelo fique \"viciado\" em certas características e ajuda imenso a prevenir o *overfitting*.\n",
    "\n",
    "---\n",
    "\n",
    "#### 6. SVR Linear (Support Vector Regression)\n",
    "Procura um hiperplano que mantenha o máximo de pontos dentro de uma margem de erro permitida ($\\epsilon$).\n",
    "\n",
    "* **`C` [0.1, 1, 10, 100]**:\n",
    "    * **Como se encaixa:** É o parâmetro de penalização. Um `C` baixo prioriza uma margem larga e um modelo simples. Um `C` alto penaliza severamente qualquer erro, tentando ajustar-se perfeitamente aos dados de treino.\n",
    "* **`epsilon` [0.01, 0.1, 0.5]**:\n",
    "    * **Porquê estes valores?** Define o \"tubo\" de tolerância. Se o erro for menor que $\\epsilon$, o modelo ignora-o. Valores como 0.5 tornam o modelo muito mais tolerante a ruído.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### 7. MLP (Multi-Layer Perceptron)\n",
    "Uma rede neural que aprende representações complexas através de camadas de neurónios.\n",
    "\n",
    "* **`hidden_layer_sizes` [(50,50,50), (100,50), (100,)]**:\n",
    "    * **Porquê estes valores?** Testamos três arquiteturas: uma profunda com três camadas `(50,50,50)`, uma piramidal `(100,50)` e uma simples `(100,)`. Isto permite avaliar se o problema é linearmente separável ou se exige abstrações profundas.\n",
    "* **`activation` ['tanh', 'relu']**:\n",
    "    * **Como se encaixa:** `relu` é a mais eficiente computacionalmente; `tanh` pode ser útil em dados normalizados para capturar curvaturas mais suaves.\n",
    "* **`alpha` [0.0001, 0.05]**:\n",
    "    * **Como se encaixa:** Parâmetro de regularização L2 (weight decay). Valores como 0.05 ajudam a \"encolher\" os pesos da rede, evitando que neurónios específicos dominem a previsão e causem instabilidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "186266a1-9cec-4131-a16e-630aaa485d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def executar_grid_search(modelo, nome_modelo, X, y, usar_scaled=False):\n",
    "    print(f\"\\nA iniciar GridSearch no modelo:'{nome_modelo}' \")\n",
    "\n",
    "    # 1. Obter o grid de parâmetros\n",
    "    param_grid = obter_params_grid(nome_modelo)\n",
    "\n",
    "    if not param_grid:\n",
    "        print(f\"‼ ATENÇÃO - Nenhum grid de hiperparametros definido para {nome_modelo} !!\")\n",
    "        return modelo\n",
    "\n",
    "    # 2. Configurar o GridSearch\n",
    "    # cv -> número de folds no Cross Validation (\"Mais folds = Mais tempo de execução\")\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=modelo,\n",
    "        param_grid=param_grid,\n",
    "        cv=3, \n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        verbose=3,\n",
    "        n_jobs=-1  # Usa todos os processadores\n",
    "    )\n",
    "\n",
    "    # 3. Treinar\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    # 4. Resultados\n",
    "    print(f\"✓ Melhores Parâmetros: {grid_search.best_params_}\")\n",
    "    print(f\"  Melhor RMSE (CV): {-grid_search.best_score_:,.2f}\")\n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa885c6-5047-4f38-bd18-1eb09605b53e",
   "metadata": {},
   "source": [
    "### Método de **Avaliação de Modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca9ced5c-bec5-4957-95ed-c66d30b6857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliar_modelo(modelo, X_train, y_train, X_val, y_val, nome_modelo):\n",
    "\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"A Treinar o modelo: '{nome_modelo}'\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Treinar\n",
    "    modelo.fit(X_train, y_train)\n",
    "\n",
    "    # Previsoes\n",
    "    y_train_pred = modelo.predict(X_train)\n",
    "    y_val_pred = modelo.predict(X_val)\n",
    "\n",
    "    # Métricas de treino\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "    # Métricas de validação\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "    # Exibir resultados\n",
    "    print(f\"\\n▶ MÉTRICAS DE TREINO:\")\n",
    "    print(f\"  RMSE: {train_rmse:,.2f}\")\n",
    "\n",
    "    print(f\"\\n▶ MÉTRICAS DE VALIDAÇÃO:\")\n",
    "    print(f\"  RMSE: {val_rmse:,.2f}\")\n",
    "\n",
    "    return {\n",
    "        'modelo': nome_modelo,\n",
    "        'train_rmse': train_rmse,\n",
    "        'val_rmse': val_rmse,\n",
    "        'modelo_treinado': modelo\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65975e59-7635-4660-952f-a451162f8416",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0755995e-7582-4d7f-b9b7-dca491ced317",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de25acce-0940-47d1-908b-3097ccadff33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar dados (importante para KNN, SVM e MLP) | Permite que todas as features contribuam equilibradamente para o modelo\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Alinhar as colunas do conjunto de teste com as colunas usadas no treino\n",
    "# (mesma ordem; preencher colunas em falta com 0)\n",
    "X_test_aligned = X_test_final.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test_aligned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58ebb16f-b6d3-4a19-9d6c-b48e820eb8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dados preparados:\n",
      "  - Treino: 150826 amostras\n",
      "  - Validação: 37707 amostras\n",
      "  - Features: 18\n"
     ]
    }
   ],
   "source": [
    "print(f\"✓ Dados preparados:\")\n",
    "print(f\"  - Treino: {X_train.shape[0]} amostras\")\n",
    "print(f\"  - Validação: {X_val.shape[0]} amostras\")\n",
    "print(f\"  - Features: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f84232ce-6d67-42f7-83b6-bd46a81548de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A iniciar GridSearch no modelo:'Linear Regression' \n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "✓ Melhores Parâmetros: {'fit_intercept': True, 'positive': False}\n",
      "  Melhor RMSE (CV): 0.54\n",
      "\n",
      "============================================================\n",
      "A Treinar o modelo: 'Linear Regression'\n",
      "============================================================\n",
      "\n",
      "▶ MÉTRICAS DE TREINO:\n",
      "  RMSE: 0.54\n",
      "\n",
      "▶ MÉTRICAS DE VALIDAÇÃO:\n",
      "  RMSE: 0.54\n",
      "\n",
      "A iniciar GridSearch no modelo:'KNN' \n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "✓ Melhores Parâmetros: {'n_neighbors': 11, 'p': 1, 'weights': 'uniform'}\n",
      "  Melhor RMSE (CV): 0.52\n",
      "\n",
      "============================================================\n",
      "A Treinar o modelo: 'KNN'\n",
      "============================================================\n",
      "\n",
      "▶ MÉTRICAS DE TREINO:\n",
      "  RMSE: 0.47\n",
      "\n",
      "▶ MÉTRICAS DE VALIDAÇÃO:\n",
      "  RMSE: 0.52\n",
      "\n",
      "A iniciar GridSearch no modelo:'Decision Tree' \n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "✓ Melhores Parâmetros: {'criterion': 'absolute_error', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
      "  Melhor RMSE (CV): 0.51\n",
      "\n",
      "============================================================\n",
      "A Treinar o modelo: 'Decision Tree'\n",
      "============================================================\n",
      "\n",
      "▶ MÉTRICAS DE TREINO:\n",
      "  RMSE: 0.50\n",
      "\n",
      "▶ MÉTRICAS DE VALIDAÇÃO:\n",
      "  RMSE: 0.52\n",
      "\n",
      "A iniciar GridSearch no modelo:'Random Forest' \n",
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "✓ Melhores Parâmetros: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "  Melhor RMSE (CV): 0.50\n",
      "\n",
      "============================================================\n",
      "A Treinar o modelo: 'Random Forest'\n",
      "============================================================\n",
      "\n",
      "▶ MÉTRICAS DE TREINO:\n",
      "  RMSE: 0.37\n",
      "\n",
      "▶ MÉTRICAS DE VALIDAÇÃO:\n",
      "  RMSE: 0.50\n",
      "\n",
      "A iniciar GridSearch no modelo:'XGBoost' \n",
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n",
      "✓ Melhores Parâmetros: {'colsample_bytree': 0.7, 'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 1000, 'subsample': 0.7}\n",
      "  Melhor RMSE (CV): 0.49\n",
      "\n",
      "============================================================\n",
      "A Treinar o modelo: 'XGBoost'\n",
      "============================================================\n",
      "\n",
      "▶ MÉTRICAS DE TREINO:\n",
      "  RMSE: 0.47\n",
      "\n",
      "▶ MÉTRICAS DE VALIDAÇÃO:\n",
      "  RMSE: 0.49\n",
      "\n",
      "A iniciar GridSearch no modelo:'SVR Linear' \n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Executar Grid Search para tuning\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m usar_scaled:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     modelo = \u001b[43mexecutar_grid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnome\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     res = avaliar_modelo(modelo, X_train_scaled, y_train, X_val_scaled, y_val, nome)\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mexecutar_grid_search\u001b[39m\u001b[34m(modelo, nome_modelo, X, y, usar_scaled)\u001b[39m\n\u001b[32m     13\u001b[39m grid_search = GridSearchCV(\n\u001b[32m     14\u001b[39m     estimator=modelo,\n\u001b[32m     15\u001b[39m     param_grid=param_grid,\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m     n_jobs=-\u001b[32m1\u001b[39m  \u001b[38;5;66;03m# Usa todos os processadores\u001b[39;00m\n\u001b[32m     20\u001b[39m )\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# 3. Treinar\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# 4. Resultados\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✓ Melhores Parâmetros: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search.best_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "modelos = obter_modelos()\n",
    "\n",
    "#Treinar os modelos e Avaliar\n",
    "resultados = []\n",
    "modelos_treinados = {}\n",
    "\n",
    "for nome, modelo in modelos.items():\n",
    "    # Decidir se usar dados normalizados\n",
    "    usar_scaled = nome in ['KNN', 'SVR Linear', 'MLP Small']\n",
    "\n",
    "    # Executar Grid Search para tuning\n",
    "    if usar_scaled:\n",
    "        modelo = executar_grid_search(modelo, nome, X_train_scaled, y_train)\n",
    "        res = avaliar_modelo(modelo, X_train_scaled, y_train, X_val_scaled, y_val, nome)\n",
    "    else:\n",
    "        modelo = executar_grid_search(modelo, nome, X_train, y_train)\n",
    "        res = avaliar_modelo(modelo, X_train, y_train, X_val, y_val, nome)\n",
    "\n",
    "    resultados.append(res)\n",
    "    modelos_treinados[nome] = {\n",
    "        'modelo': res['modelo_treinado'],\n",
    "        'usar_scaled': usar_scaled\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b680543-3732-4246-84d3-23839765cdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Criar subplots para todos os modelos\n",
    "n_modelos = len(modelos_treinados)\n",
    "n_cols = 2\n",
    "n_rows = (n_modelos + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "\n",
    "# Garantir que axes seja sempre um array 1D\n",
    "if n_rows == 1 and n_cols == 1:\n",
    "    axes = np.array([axes])\n",
    "elif n_rows == 1:\n",
    "    axes = axes  # Já é 1D quando n_rows=1\n",
    "else:\n",
    "    axes = axes.flatten()\n",
    "\n",
    "for idx, (nome_modelo, info_modelo) in enumerate(modelos_treinados.items()):\n",
    "    modelo_obj = info_modelo['modelo']\n",
    "    usar_scaled_viz = info_modelo['usar_scaled']\n",
    "    \n",
    "    # Fazer previsões no conjunto de validação\n",
    "    if usar_scaled_viz:\n",
    "        y_pred = modelo_obj.predict(X_val_scaled)\n",
    "    else:\n",
    "        y_pred = modelo_obj.predict(X_val)\n",
    "    \n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Plotar previsões vs real\n",
    "    ax.plot(y_val, y_pred, c='b', marker='o', linestyle='', alpha=0.6, markersize=4)\n",
    "    ax.plot(y_val, y_val, c='r', linestyle='--', linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel('Valor Real (log)', fontsize=10)\n",
    "    ax.set_ylabel('Valor Predito (log)', fontsize=10)\n",
    "    ax.set_title(f'Previsões vs Real - {nome_modelo}', fontsize=12, fontweight='bold')\n",
    "    ax.legend(['Validação', 'Perfect Regressor'], loc='upper left', fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Remover subplots vazios se houver\n",
    "for idx in range(n_modelos, len(axes)):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b3a95f-ea2b-4142-8d1b-8d92dfda248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparação final\n",
    "print(f\"\\n\\n{'='*80}\")\n",
    "print(\" ■ COMPARAÇÃO DE MODELOS (ordenados por RMSE de validação)\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados = df_resultados.sort_values('val_rmse', ascending=True)\n",
    "\n",
    "print(df_resultados[['modelo', 'val_rmse']].to_string(index=False))\n",
    "\n",
    "# Melhor modelo\n",
    "melhor_resultado = df_resultados.iloc[0]\n",
    "print(f\"\\n\\n ▶ MELHOR MODELO: {melhor_resultado['modelo']}\")\n",
    "print(f\"  RMSE Validação: {melhor_resultado['val_rmse']:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403454b3-bc1a-4a64-9ffe-973ee8424cec",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Salvar Submissão & Fazer Log do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac016174-10a2-4192-9ad6-117ddea0e009",
   "metadata": {},
   "source": [
    "### Método para **guardar log das configurações do modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33f988e-aa0c-4e7f-b847-12ae3414d1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvar_submissao_log(df_sub, modelo_treinado, nome_modelo, metricas):\n",
    "    pasta = 'submissoes'\n",
    "    os.makedirs(pasta, exist_ok=True)\n",
    "\n",
    "    # 1. Listar ficheiros e encontrar o maior ID existente\n",
    "    ficheiros = os.listdir(pasta)\n",
    "    ids_existentes = []\n",
    "\n",
    "    for f in ficheiros:\n",
    "        # Verifica se o arquivo segue o padrão 'submission_X.csv'\n",
    "        if f.startswith('submission_') and f.endswith('.csv'):\n",
    "            try:\n",
    "                # Extrai apenas o número do nome do arquivo\n",
    "                # Ex: 'submission_12.csv' -> '12'\n",
    "                numero_str = f.replace('submission_', '').replace('.csv', '')\n",
    "                ids_existentes.append(int(numero_str))\n",
    "            except ValueError:\n",
    "                continue # Salta ficheiros que não tenham número válido\n",
    "\n",
    "    # Se a lista estiver vazia, começa do 1. Se não, pega o maior + 1\n",
    "    if not ids_existentes:\n",
    "        next_id = 1\n",
    "    else:\n",
    "        next_id = max(ids_existentes) + 1\n",
    "\n",
    "    # 2. Definir nomes dos ficheiros\n",
    "    filename_csv = f\"{pasta}/submission_{next_id}.csv\"\n",
    "    filename_json = f\"{pasta}/submission_{next_id}_params.json\"\n",
    "\n",
    "    # 3. Salvar CSV\n",
    "    df_sub.to_csv(filename_csv, index=False)\n",
    "\n",
    "    # 4. Extrair Hiperparâmetros\n",
    "    try:\n",
    "        params = modelo_treinado.get_params()\n",
    "    except:\n",
    "        params = {\"info\": \"Não foi possível extrair params\"}\n",
    "\n",
    "    # 5. Metadados\n",
    "    metadados = {\n",
    "        \"id\": next_id,\n",
    "        \"modelo\": nome_modelo,\n",
    "        \"performance_validacao\": metricas,\n",
    "        \"hiperparametros\": params\n",
    "    }\n",
    "\n",
    "    # 6. Salvar JSON\n",
    "    with open(filename_json, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metadados, f, indent=4, default=str)\n",
    "\n",
    "    print(f\"\\n✓ Submissão #{next_id} salva com sucesso!\")\n",
    "    print(f\" ▱ {filename_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1955caba-5b34-40c9-bb71-f0c93565a2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "melhor_modelo_nome = melhor_resultado['modelo']\n",
    "\n",
    "melhor_modelo = modelos_treinados[melhor_modelo_nome]['modelo']\n",
    "\n",
    "usar_scaled = modelos_treinados[melhor_modelo_nome]['usar_scaled']\n",
    "\n",
    "\n",
    "if usar_scaled:\n",
    "    X_test_usar = X_test_scaled\n",
    "\n",
    "else:\n",
    "    X_test_usar = X_test_aligned\n",
    "\n",
    "pred_log = melhor_modelo.predict(X_test_usar)\n",
    "\n",
    "pred_reais = np.expm1(pred_log)\n",
    "\n",
    "# Submissão\n",
    "df_submissao = pd.DataFrame({\n",
    "\n",
    "    'id': df_teste.index,\n",
    "\n",
    "    'price': pred_reais\n",
    "\n",
    "})\n",
    "\n",
    "salvar_submissao_log(df_submissao, melhor_modelo, melhor_modelo_nome, melhor_resultado.to_dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
