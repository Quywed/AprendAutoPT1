{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caa168ab-4500-4d22-aba9-989df3e3274d",
   "metadata": {},
   "source": [
    "# 1. Import de Bibliotecas e de Algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c076668-f3b0-4c9b-849a-b4d4235502b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "# Importar modelos\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0f614e-fa19-4055-ab8b-e4ed7ffe1037",
   "metadata": {},
   "source": [
    "# 2. FEATURE ENGINEERING - Extracao e Limpeza de Dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7755fa7-15bb-4e13-9d7e-9c5da12eae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engeneering(df):\n",
    "    df_eng = df.copy()\n",
    "    \n",
    "    # --- LIMPEZA INICIAL ---\n",
    "    df_eng = df_eng.drop_duplicates()\n",
    "    df_eng['hp'] = df['engine'].str.extract(r'(\\d+\\.?\\d*)HP', expand=False).astype(float)\n",
    "    df_eng['liters'] = df['engine'].str.extract(r'(\\d+\\.?\\d*)L\\s', expand=False).astype(float)\n",
    "    \n",
    "    # --- Idade e Uso ---\n",
    "    var_ano_atual = date.today().year\n",
    "    df_eng['car_age'] = var_ano_atual - df_eng['model_year']\n",
    "    df_eng['car_age'] = df_eng['car_age'].replace(0, 1)\n",
    "    \n",
    "    # --- Cilindrada ---\n",
    "    df_eng['cylinders'] = df['engine'].str.extract(r'(\\d+)\\s+Cylinder', expand=False)\n",
    "    df_eng['cylinders'] = df_eng['cylinders'].fillna(df['engine'].str.extract(r'V(\\d+)', expand=False))\n",
    "    df_eng['cylinders'] = df_eng['cylinders'].astype(float)\n",
    "    \n",
    "    # --- Tecnologias de Motor ---\n",
    "    df_eng['is_turbo'] = df['engine'].str.contains(r'(?i)turbo', na=False).astype(int)\n",
    "    df_eng['turbo_type'] = df['engine'].str.extract(r'(Twin Turbo|Turbo)', expand=False)\n",
    "    df_eng['valve_train'] = df['engine'].str.extract(r'(DOHC|OHV|SOHC)', expand=False) \n",
    "    df_eng['fuel_injection'] = df['engine'].str.extract(r'(PDI|GDI|MPFI)', expand=False)\n",
    "    \n",
    "    # Miles per year\n",
    "    df_eng['miles_p_year'] = df_eng['milage'] / df_eng['car_age']\n",
    "    \n",
    "    # --- FUEL TYPE ---\n",
    "    def clean_fuel(val):\n",
    "        s = str(val).lower()\n",
    "        if 'hybrid' in s:\n",
    "            return 'Hybrid'\n",
    "        elif 'not supported' in s:\n",
    "            return 'EV'\n",
    "        else:\n",
    "            return val\n",
    "    df_eng['fuel_type'] = df_eng['fuel_type'].apply(clean_fuel)\n",
    "    \n",
    "    # --- TRANSMISSION TYPE ---\n",
    "    def clean_transmission(val):\n",
    "        s = str(val).lower()\n",
    "        if 'automatic' in s or 'a/t' in s or 'cvt' in s:\n",
    "            return 'Automatico'\n",
    "        elif 'manual' in s or 'm/t' in s:\n",
    "            return 'Manual'\n",
    "        else:\n",
    "            return 'Outro'\n",
    "    df_eng['transmission_type'] = df_eng['transmission'].apply(clean_transmission)\n",
    "    \n",
    "    # --- Cores ---\n",
    "    top_ext_colors = df_eng['ext_col'].value_counts().nlargest(10).index\n",
    "    def simplificar_cor_ext(cor):\n",
    "        return cor if cor in top_ext_colors else 'Other'\n",
    "    df_eng['ext_col_simple'] = df_eng['ext_col'].apply(simplificar_cor_ext)\n",
    "    \n",
    "    top_int_colors = df_eng['int_col'].value_counts().nlargest(10).index\n",
    "    def simplificar_cor_int(cor):\n",
    "        return cor if cor in top_int_colors else 'Other'\n",
    "    df_eng['int_col_simple'] = df_eng['int_col'].apply(simplificar_cor_int)\n",
    "    \n",
    "    # --- Tratamento de Nulos ---\n",
    "    cols_texto = df_eng.select_dtypes(include=['object']).columns\n",
    "    df_eng[cols_texto] = df_eng[cols_texto].replace('-', 'Unknown').fillna('Unknown')\n",
    "    df_eng['clean_title'] = df_eng['clean_title'].replace('Unknown', 'No')\n",
    "    \n",
    "    # --- Acidente ---\n",
    "    def verificar_acidente(valor):\n",
    "        return 0 if 'None' in str(valor) else 1\n",
    "    df_eng['accident_clean'] = df_eng['accident'].apply(verificar_acidente)\n",
    "    \n",
    "    return df_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220d4bec-25ba-4934-94ae-5b1b7fde8338",
   "metadata": {},
   "source": [
    "# 3. PREPARA√á√ÉO DE DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a271f79-8b4a-4e82-973c-5c6148d06d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_dados(df_treino, df_teste):\n",
    "    \"\"\"Prepara dados para modelagem\"\"\"\n",
    "    \n",
    "    # Aplicar feature engineering\n",
    "    df_treino_eng = feature_engeneering(df_treino)\n",
    "    df_teste_eng = feature_engeneering(df_teste)\n",
    "    \n",
    "    # Separar target\n",
    "    y = df_treino_eng['price']\n",
    "    X = df_treino_eng.drop('price', axis=1)\n",
    "    X_test = df_teste_eng.copy()\n",
    "    \n",
    "    # Selecionar features relevantes\n",
    "    features_numericas = ['hp', 'liters', 'car_age', 'cylinders', 'miles_p_year', \n",
    "                          'milage', 'model_year', 'is_turbo']\n",
    "    \n",
    "    features_categoricas = ['brand', 'model', 'fuel_type', 'transmission_type', \n",
    "                           'ext_col_simple', 'int_col_simple', 'clean_title', \n",
    "                           'turbo_type', 'valve_train', 'fuel_injection']\n",
    "    \n",
    "    # Criar dataset num√©rico\n",
    "    X_num = X[features_numericas].fillna(0)\n",
    "    X_test_num = X_test[features_numericas].fillna(0)\n",
    "    \n",
    "    # Encodar vari√°veis categ√≥ricas\n",
    "    X_cat = X[features_categoricas].copy()\n",
    "    X_test_cat = X_test[features_categoricas].copy()\n",
    "    \n",
    "    encoders = {}\n",
    "    for col in features_categoricas:\n",
    "        le = LabelEncoder()\n",
    "        # Fit no treino\n",
    "        X_cat[col] = X_cat[col].astype(str)\n",
    "        le.fit(X_cat[col])\n",
    "        X_cat[col] = le.transform(X_cat[col])\n",
    "        \n",
    "        # Transform no teste (tratando categorias novas)\n",
    "        X_test_cat[col] = X_test_cat[col].astype(str)\n",
    "        X_test_cat[col] = X_test_cat[col].apply(\n",
    "            lambda x: le.transform([x])[0] if x in le.classes_ else -1\n",
    "        )\n",
    "        encoders[col] = le\n",
    "    \n",
    "    # Concatenar features\n",
    "    X_final = pd.concat([X_num, X_cat], axis=1)\n",
    "    X_test_final = pd.concat([X_test_num, X_test_cat], axis=1)\n",
    "    \n",
    "    return X_final, y, X_test_final, encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8195a7cf-1576-4570-9e78-fb1a6cd84404",
   "metadata": {},
   "source": [
    "# 4. DEFINI√á√ÉO DE MODELOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08236dd4-e05b-4131-bb66-cbf6ff847536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_modelos():\n",
    "    \"\"\"Retorna dicion√°rio com todos os modelos dispon√≠veis\"\"\"\n",
    "    \n",
    "    modelos = {\n",
    "        # Regress√£o Linear\n",
    "        #'Linear Regression': LinearRegression(),\n",
    "        \n",
    "        # K-Nearest Neighbors\n",
    "        #'#KNN': KNeighborsRegressor(n_neighbors=5),\n",
    "        \n",
    "        # √Årvores de Decis√£o\n",
    "        #'Decision Tree': DecisionTreeRegressor(max_depth=10, random_state=42),\n",
    "        \n",
    "        # Random Forest e variantes\n",
    "        #'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=15, \n",
    "                                               #random_state=42, n_jobs=-1),\n",
    "\n",
    "        'XGBoost': xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, \n",
    "                                    max_depth=7, random_state=42, n_jobs=-1),\n",
    "        \n",
    "        # Support Vector Machines\n",
    "        #'SVR Linear': SVR(kernel='linear', C=1.0),\n",
    "        #SVR RBF': SVR(kernel='rbf', C=1.0, gamma='scale'),\n",
    "        \n",
    "        # Redes Neuronais\n",
    "        #'MLP Small': MLPRegressor(hidden_layer_sizes=(100,), max_iter=500, \n",
    "                                  #random_state=42, early_stopping=True),\n",
    "        \n",
    "        #'MLP Deep': MLPRegressor(hidden_layer_sizes=(100, 50, 25), max_iter=500, \n",
    "                                 #random_state=42, early_stopping=True)\n",
    "    }\n",
    "    \n",
    "    return modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c102bd35-0181-458e-bd8c-174dcd8a59e9",
   "metadata": {},
   "source": [
    "# 5. GridSearchCV - Grid Search com Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b197afb0-58d0-42b8-8035-f1242807e467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "092de71f-bf19-47ce-bdb7-3571e098690c",
   "metadata": {},
   "source": [
    "# 6. AVALIA√á√ÉO DE MODELOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e5ca01-d83a-4a23-83d3-f467ea95343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliar_modelo(modelo, X_train, y_train, X_val, y_val, nome_modelo):\n",
    "    \"\"\"Treina e avalia um modelo\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Treinando: {nome_modelo}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Treinar\n",
    "    modelo.fit(X_train, y_train)\n",
    "    \n",
    "    # Predi√ß√µes\n",
    "    y_train_pred = modelo.predict(X_train)\n",
    "    y_val_pred = modelo.predict(X_val)\n",
    "    \n",
    "    # M√©tricas de treino\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    \n",
    "    # M√©tricas de valida√ß√£o\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "    val_r2 = r2_score(y_val, y_val_pred)\n",
    "    val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "    \n",
    "    # Exibir resultados\n",
    "    print(f\"\\nüìä M√âTRICAS DE TREINO:\")\n",
    "    print(f\"  RMSE: ${train_rmse:,.2f}\")\n",
    "    print(f\"  R¬≤: {train_r2:.4f}\")\n",
    "    print(f\"  MAE: ${train_mae:,.2f}\")\n",
    "    \n",
    "    print(f\"\\nüìä M√âTRICAS DE VALIDA√á√ÉO:\")\n",
    "    print(f\"  RMSE: ${val_rmse:,.2f}\")\n",
    "    print(f\"  R¬≤: {val_r2:.4f}\")\n",
    "    print(f\"  MAE: ${val_mae:,.2f}\")\n",
    "    \n",
    "    # Verificar overfitting\n",
    "    overfit = train_r2 - val_r2\n",
    "    if overfit > 0.1:\n",
    "        print(f\"\\n‚ö†Ô∏è  Poss√≠vel overfitting detectado (diferen√ßa R¬≤: {overfit:.4f})\")\n",
    "    \n",
    "    return {\n",
    "        'modelo': nome_modelo,\n",
    "        'train_rmse': train_rmse,\n",
    "        'train_r2': train_r2,\n",
    "        'train_mae': train_mae,\n",
    "        'val_rmse': val_rmse,\n",
    "        'val_r2': val_r2,\n",
    "        'val_mae': val_mae,\n",
    "        'modelo_treinado': modelo\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74ed31d-3e69-4843-a906-ab208a792bb3",
   "metadata": {},
   "source": [
    "# 7. TREINAR MODELOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ac6f85-9dad-4fcd-8f5e-cbf989845ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinar_modelos(df_treino, df_teste, modelos_selecionados=None):\n",
    "    \"\"\"\n",
    "    Treina e compara m√∫ltiplos modelos\n",
    "    \n",
    "    Args:\n",
    "        df_treino: DataFrame de treino\n",
    "        df_teste: DataFrame de teste\n",
    "        modelos_selecionados: Lista com nomes dos modelos a treinar (None = todos)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üîÑ Preparando dados...\")\n",
    "    X, y, X_test, encoders = preparar_dados(df_treino, df_teste)\n",
    "    \n",
    "    # Split treino/valida√ß√£o\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Normalizar dados (importante para KNN, SVM e MLP)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    \n",
    "    \n",
    "    print(f\"‚úÖ Dados preparados:\")\n",
    "    print(f\"  - Treino: {X_train.shape[0]} amostras\")\n",
    "    print(f\"  - Valida√ß√£o: {X_val.shape[0]} amostras\")\n",
    "    print(f\"  - Features: {X_train.shape[1]}\")\n",
    "    \n",
    "    # Obter modelos\n",
    "    todos_modelos = obter_modelos()\n",
    "    \n",
    "    # Filtrar modelos se especificado\n",
    "    if modelos_selecionados:\n",
    "        modelos = {k: v for k, v in todos_modelos.items() if k in modelos_selecionados}\n",
    "    else:\n",
    "        modelos = todos_modelos\n",
    "    \n",
    "    # Treinar modelos\n",
    "    resultados = []\n",
    "    modelos_treinados = {}\n",
    "    \n",
    "    for nome, modelo in modelos.items():\n",
    "        # Decidir se usar dados normalizados\n",
    "        usar_scaled = nome in ['KNN', 'SVR Linear', 'SVR RBF', 'MLP Small', 'MLP Deep']\n",
    "        \n",
    "        if usar_scaled:\n",
    "            res = avaliar_modelo(modelo, X_train_scaled, y_train, \n",
    "                                X_val_scaled, y_val, nome)\n",
    "        else:\n",
    "            res = avaliar_modelo(modelo, X_train, y_train, \n",
    "                                X_val, y_val, nome)\n",
    "        \n",
    "        resultados.append(res)\n",
    "        modelos_treinados[nome] = {\n",
    "            'modelo': res['modelo_treinado'],\n",
    "            'usar_scaled': usar_scaled\n",
    "        }\n",
    "    \n",
    "    # Compara√ß√£o final\n",
    "    print(f\"\\n\\n{'='*80}\")\n",
    "    print(\"üìà COMPARA√á√ÉO DE MODELOS (ordenados por R¬≤ de valida√ß√£o)\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "    df_resultados = df_resultados.sort_values('val_r2', ascending=False)\n",
    "    \n",
    "    print(df_resultados[['modelo', 'val_rmse', 'val_r2', 'val_mae']].to_string(index=False))\n",
    "    \n",
    "    # Melhor modelo\n",
    "    melhor = df_resultados.iloc[0]\n",
    "    print(f\"\\n\\nüèÜ MELHOR MODELO: {melhor['modelo']}\")\n",
    "    print(f\"  R¬≤ Valida√ß√£o: {melhor['val_r2']:.4f}\")\n",
    "    print(f\"  RMSE Valida√ß√£o: ${melhor['val_rmse']:,.2f}\")\n",
    "    \n",
    "    return df_resultados, modelos_treinados, scaler, (X_test, X_test_scaled)    #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2617259-8839-42b6-90ae-342a9f94ee44",
   "metadata": {},
   "source": [
    "# 8. Guardar Hiperparametros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44766b71-4b34-414b-9a42-57479e8fa907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvar_submissao_log(df_sub, modelo_treinado, nome_modelo, metricas):\n",
    "    \"\"\"\n",
    "    Salva CSV e JSON incrementando o ID com base no maior n√∫mero encontrado.\n",
    "    \"\"\"\n",
    "    pasta = 'submissoes'\n",
    "    os.makedirs(pasta, exist_ok=True)\n",
    "    \n",
    "    # 1. Listar arquivos e encontrar o maior ID existente\n",
    "    arquivos = os.listdir(pasta)\n",
    "    ids_existentes = []\n",
    "    \n",
    "    for f in arquivos:\n",
    "        # Verifica se o arquivo segue o padr√£o 'submission_X.csv'\n",
    "        if f.startswith('submission_') and f.endswith('.csv'):\n",
    "            try:\n",
    "                # Extrai apenas o n√∫mero do nome do arquivo\n",
    "                # Ex: 'submission_12.csv' -> '12'\n",
    "                numero_str = f.replace('submission_', '').replace('.csv', '')\n",
    "                ids_existentes.append(int(numero_str))\n",
    "            except ValueError:\n",
    "                continue # Pula arquivos que n√£o tenham n√∫mero v√°lido\n",
    "    \n",
    "    # Se a lista estiver vazia, come√ßa do 1. Se n√£o, pega o maior + 1\n",
    "    if not ids_existentes:\n",
    "        next_id = 1\n",
    "    else:\n",
    "        next_id = max(ids_existentes) + 1\n",
    "    \n",
    "    # 2. Definir nomes dos arquivos\n",
    "    filename_csv = f\"{pasta}/submission_{next_id}.csv\"\n",
    "    filename_json = f\"{pasta}/submission_{next_id}_params.json\"\n",
    "    \n",
    "    # 3. Salvar CSV\n",
    "    df_sub.to_csv(filename_csv, index=False)\n",
    "    \n",
    "    # 4. Extrair Hiperpar√¢metros\n",
    "    try:\n",
    "        params = modelo_treinado.get_params()\n",
    "    except:\n",
    "        params = {\"info\": \"N√£o foi poss√≠vel extrair params\"}\n",
    "        \n",
    "    # 5. Metadata\n",
    "    metadata = {\n",
    "        \"id\": next_id,\n",
    "        \"modelo\": nome_modelo,\n",
    "        \"performance_validacao\": metricas,\n",
    "        \"hiperparametros\": params\n",
    "    }\n",
    "    \n",
    "    # 6. Salvar JSON\n",
    "    with open(filename_json, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metadata, f, indent=4, default=str)\n",
    "        \n",
    "    print(f\"\\n‚úÖ Submiss√£o #{next_id} salva com sucesso!\")\n",
    "    print(f\"   üìÇ {filename_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e765c6f0-2c46-4777-8d59-5b14334ee6f5",
   "metadata": {},
   "source": [
    "# Fim - Execucao do Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4958089-b9ac-4282-ae06-efaf20274f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Carregar dados\n",
    "    df_treino = pd.read_csv('dados/train.csv', index_col='id')\n",
    "    df_teste = pd.read_csv('dados/test.csv', index_col='id')\n",
    "    \n",
    "    # OP√á√ÉO 1: Treinar todos os modelos\n",
    "    print(\"üöÄ TREINANDO TODOS OS MODELOS\\n\")\n",
    "    resultados, modelos, scaler, dados_teste = treinar_modelos(df_treino, df_teste)\n",
    "    \n",
    "    # OP√á√ÉO 2: Treinar apenas modelos espec√≠ficos\n",
    "    # modelos_escolhidos = ['Random Forest', 'XGBoost', 'MLP Deep']\n",
    "    # resultados, modelos, scaler, dados_teste = treinar_modelos(\n",
    "    #     df_treino, df_teste, modelos_selecionados=modelos_escolhidos\n",
    "    # )\n",
    "    \n",
    "    # Gerar previs√µes com o melhor modelo\n",
    "    melhor_resultado = resultados.iloc[0]\n",
    "    melhor_nome = melhor_resultado['modelo']\n",
    "    melhor_config = modelos[melhor_nome]\n",
    "    modelo_final = melhor_config['modelo']\n",
    "    \n",
    "    print(f\"\\nüèÜ Modelo Escolhido para Submiss√£o: {melhor_nome}\")\n",
    "    \n",
    "    # --- PREVIS√ÉO ---\n",
    "    X_test, X_test_scaled = dados_teste\n",
    "    if melhor_config['usar_scaled']:\n",
    "        previsoes = modelo_final.predict(X_test_scaled)\n",
    "    else:\n",
    "        previsoes = modelo_final.predict(X_test)\n",
    "    \n",
    "    # --- PREPARAR DATAFRAME ---\n",
    "    df_submissao = pd.DataFrame({\n",
    "        'id': df_teste.index,\n",
    "        'price': previsoes\n",
    "    })\n",
    "    \n",
    "    # --- EXTRAIR M√âTRICAS DO MELHOR MODELO PARA SALVAR NO LOG ---\n",
    "    metricas_log = {\n",
    "        'val_rmse': melhor_resultado['val_rmse'],\n",
    "        'val_r2': melhor_resultado['val_r2'],\n",
    "        'val_mae': melhor_resultado['val_mae']\n",
    "    }\n",
    "    \n",
    "    # --- SALVAR COM CONTROLE DE VERS√ÉO E LOG ---\n",
    "    salvar_submissao_log(df_submissao, modelo_final, melhor_nome, metricas_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ce042e-beca-4e79-ba62-4d872ee9fd34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
