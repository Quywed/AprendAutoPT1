{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caa168ab-4500-4d22-aba9-989df3e3274d",
   "metadata": {},
   "source": [
    "# 1. Import de Bibliotecas e de Algoritmos (v4 - Melhorado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c076668-f3b0-4c9b-849a-b4d4235502b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import os\n",
    "import json\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Importar modelos\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "# Configura√ß√µes para melhoria de performance\n",
    "N_ESTIMATORS_XGB = 2000 # Aumentado para melhor performance com learning_rate baixo\n",
    "LEARNING_RATE_XGB = 0.01 # Diminu√≠do para melhor precis√£o\n",
    "N_ESTIMATORS_GBM = 1500\n",
    "LEARNING_RATE_GBM = 0.01\n",
    "N_ESTIMATORS_RF = 500\n",
    "KFOLD_SPLITS = 5 # Usar K-Fold para valida√ß√£o mais robusta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0f614e-fa19-4055-ab8b-e4ed7ffe1037",
   "metadata": {},
   "source": [
    "# 2. FEATURE ENGINEERING - Extracao e Limpeza de Dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7755fa7-15bb-4e13-9d7e-9c5da12eae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engeneering(df):\n",
    "    df_eng = df.copy()\n",
    "\n",
    "    # --- LIMPEZA INICIAL ---\n",
    "    df_eng = df_eng.drop_duplicates()\n",
    "    df_eng['hp'] = df['engine'].str.extract(r'(\\d+\\.?\\d*)HP', expand=False).astype(float)\n",
    "    df_eng['liters'] = df['engine'].str.extract(r'(\\d+\\.?\\d*)L\\s', expand=False).astype(float)\n",
    "\n",
    "    # --- Idade e Uso ---\n",
    "    var_ano_atual = date.today().year\n",
    "    df_eng['car_age'] = var_ano_atual - df_eng['model_year']\n",
    "    df_eng['car_age'] = df_eng['car_age'].replace(0, 1)\n",
    "\n",
    "    # --- Cilindrada ---\n",
    "    df_eng['cylinders'] = df['engine'].str.extract(r'(\\d+)\\s+Cylinder', expand=False)\n",
    "    df_eng['cylinders'] = df_eng['cylinders'].fillna(df['engine'].str.extract(r'V(\\d+)', expand=False))\n",
    "    df_eng['cylinders'] = df_eng['cylinders'].astype(float)\n",
    "\n",
    "    # --- Tecnologias de Motor ---\n",
    "    df_eng['is_turbo'] = df['engine'].str.contains(r'(?i)turbo', na=False).astype(int)\n",
    "    df_eng['turbo_type'] = df['engine'].str.extract(r'(Twin Turbo|Turbo)', expand=False)\n",
    "    df_eng['valve_train'] = df['engine'].str.extract(r'(DOHC|OHV|SOHC)', expand=False) \n",
    "    df_eng['fuel_injection'] = df['engine'].str.extract(r'(PDI|GDI|MPFI)', expand=False)\n",
    "\n",
    "    # Miles per year\n",
    "    df_eng['miles_p_year'] = df_eng['milage'] / df_eng['car_age']\n",
    "\n",
    "    # --- FUEL TYPE ---\n",
    "    def clean_fuel(val):\n",
    "        s = str(val).lower()\n",
    "        if 'hybrid' in s:\n",
    "            return 'Hybrid'\n",
    "        elif 'not supported' in s:\n",
    "            return 'EV'\n",
    "        else:\n",
    "            return val\n",
    "    df_eng['fuel_type'] = df_eng['fuel_type'].apply(clean_fuel)\n",
    "\n",
    "    # --- TRANSMISSION TYPE ---\n",
    "    def clean_transmission(val):\n",
    "        s = str(val).lower()\n",
    "        if 'automatic' in s or 'a/t' in s or 'cvt' in s:\n",
    "            return 'Automatico'\n",
    "        elif 'manual' in s or 'm/t' in s:\n",
    "            return 'Manual'\n",
    "        else:\n",
    "            return 'Outro'\n",
    "    df_eng['transmission_type'] = df_eng['transmission'].apply(clean_transmission)\n",
    "\n",
    "    # --- Cores (Manter original para Target Encoding)\n",
    "    # top_ext_colors = df_eng['ext_col'].value_counts().nlargest(10).index\n",
    "    # def simplificar_cor_ext(cor):\n",
    "    #     return cor if cor in top_ext_colors else 'Other'\n",
    "    # df_eng['ext_col_simple'] = df_eng['ext_col'].apply(simplificar_cor_ext)\n",
    "    df_eng['ext_col_simple'] = df_eng['ext_col'] # Usar a coluna original para Target Encoding\n",
    "\n",
    "    # top_int_colors = df_eng['int_col'].value_counts().nlargest(10).index\n",
    "    # def simplificar_cor_int(cor):\n",
    "    #     return cor if cor in top_int_colors else 'Other'\n",
    "    # df_eng['int_col_simple'] = df_eng['int_col'].apply(simplificar_cor_int)\n",
    "    df_eng['int_col_simple'] = df_eng['int_col'] # Usar a coluna original para Target Encoding\n",
    "\n",
    "    # --- Tratamento de Nulos ---\n",
    "    cols_texto = df_eng.select_dtypes(include=['object']).columns\n",
    "    df_eng[cols_texto] = df_eng[cols_texto].replace('-', 'Unknown').fillna('Unknown')\n",
    "    df_eng['clean_title'] = df_eng['clean_title'].replace('Unknown', 'No')\n",
    "\n",
    "    # --- Acidente ---\n",
    "    def verificar_acidente(valor):\n",
    "        return 0 if 'None' in str(valor) else 1\n",
    "    df_eng['accident_clean'] = df_eng['accident'].apply(verificar_acidente)\n",
    "\n",
    "    # 1. R√°cio de Pot√™ncia por Litro (Efici√™ncia do motor)\n",
    "    df_eng['hp_per_liter'] = df_eng['hp'] / (df_eng['liters'].replace(0, 0.001))\n",
    "\n",
    "    # 2. R√°cio de Pot√™ncia por Cilindro\n",
    "    df_eng['hp_per_cylinder'] = df_eng['hp'] / (df_eng['cylinders'].replace(0, 0.001))\n",
    "\n",
    "    # 3. Log na Quilometragem (Milage)\n",
    "    df_eng['milage_log'] = np.log1p(df_eng['milage'])\n",
    "    \n",
    "    # 4. Feature de Pre√ßo/Idade (Indicador de deprecia√ß√£o)\n",
    "    df_eng['price_depreciation_indicator'] = df_eng['milage'] / (df_eng['car_age'] * df_eng['hp'].replace(0, 1))\n",
    "\n",
    "    return df_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220d4bec-25ba-4934-94ae-5b1b7fde8338",
   "metadata": {},
   "source": [
    "# 3. PREPARA√á√ÉO DE DADOS (Com Target Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a271f79-8b4a-4e82-973c-5c6148d06d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_dados(df_treino, df_teste):\n",
    "    \"\"\"Prepara dados para modelagem usando Target Encoding\"\"\"\n",
    "\n",
    "    # Aplicar feature engineering\n",
    "    df_treino_eng = feature_engeneering(df_treino)\n",
    "    df_teste_eng = feature_engeneering(df_teste)\n",
    "\n",
    "    # Separar target e aplicar Log Transformation\n",
    "    y = df_treino_eng['price']\n",
    "    y_log = np.log1p(y)\n",
    "    X = df_treino_eng.drop('price', axis=1)\n",
    "    X_test = df_teste_eng.copy()\n",
    "\n",
    "    # Selecionar features relevantes\n",
    "    features_numericas = ['hp', 'liters', 'car_age', 'cylinders', 'miles_p_year', \n",
    "                          'milage_log', 'model_year', 'is_turbo', 'hp_per_liter', \n",
    "                          'hp_per_cylinder', 'price_depreciation_indicator', 'accident_clean']\n",
    "\n",
    "    features_categoricas = ['brand', 'model', 'fuel_type', 'transmission_type', \n",
    "                           'ext_col_simple', 'int_col_simple', 'clean_title', \n",
    "                           'turbo_type', 'valve_train', 'fuel_injection']\n",
    "\n",
    "    # Criar dataset num√©rico\n",
    "    X_num = X[features_numericas].fillna(0)\n",
    "    X_test_num = X_test[features_numericas].fillna(0)\n",
    "\n",
    "    # Target Encoding para vari√°veis categ√≥ricas\n",
    "    X_cat = X[features_categoricas].copy()\n",
    "    X_test_cat = X_test[features_categoricas].copy()\n",
    "\n",
    "    encoders = {}\n",
    "    for col in features_categoricas:\n",
    "        # TargetEncoder √© mais robusto que LabelEncoder para regress√£o\n",
    "        te = TargetEncoder(cols=[col], smoothing=0.2)\n",
    "        \n",
    "        # Fit no treino e transform no treino e teste\n",
    "        X_cat[col] = te.fit_transform(X_cat[col], y_log)\n",
    "        X_test_cat[col] = te.transform(X_test_cat[col])\n",
    "        encoders[col] = te\n",
    "\n",
    "    # Concatenar features\n",
    "    X_final = pd.concat([X_num, X_cat], axis=1)\n",
    "    X_test_final = pd.concat([X_test_num, X_test_cat], axis=1)\n",
    "    \n",
    "    # Tratar NaN que podem surgir do Target Encoding em categorias novas no teste\n",
    "    X_test_final = X_test_final.fillna(X_final.mean())\n",
    "\n",
    "    return X_final, y_log, X_test_final, encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8195a7cf-1576-4570-9e78-fb1a6cd84404",
   "metadata": {},
   "source": [
    "# 4. DEFINI√á√ÉO DE MODELOS (Otimizados para Stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08236dd4-e05b-4131-bb66-cbf6ff847536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_modelos_base():\n",
    "    \"\"\"Retorna dicion√°rio com modelos base otimizados para Stacking\"\"\"\n",
    "\n",
    "    modelos = {\n",
    "        'XGBoost': xgb.XGBRegressor(\n",
    "            n_estimators=N_ESTIMATORS_XGB, learning_rate=LEARNING_RATE_XGB, \n",
    "            max_depth=6, subsample=0.7, colsample_bytree=0.7, \n",
    "            reg_alpha=0.1, reg_lambda=0.1, # Adicionado Regulariza√ß√£o\n",
    "            random_state=42, n_jobs=-1\n",
    "        ),\n",
    "        'GradientBoosting': GradientBoostingRegressor(\n",
    "            n_estimators=N_ESTIMATORS_GBM, learning_rate=LEARNING_RATE_GBM, \n",
    "            max_depth=5, subsample=0.7, random_state=42\n",
    "        ),\n",
    "        'RandomForest': RandomForestRegressor(\n",
    "            n_estimators=N_ESTIMATORS_RF, max_depth=18, min_samples_split=5, \n",
    "            random_state=42, n_jobs=-1\n",
    "        )\n",
    "    }\n",
    "\n",
    "    return modelos\n",
    "\n",
    "def obter_meta_learner():\n",
    "    \"\"\"Retorna o modelo Meta-Learner para Stacking\"\"\"\n",
    "    # Ridge √© um bom meta-learner, pois √© r√°pido e regularizado\n",
    "    return Ridge(alpha=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c102bd35-0181-458e-bd8c-174dcd8a59e9",
   "metadata": {},
   "source": [
    "# 5. Implementa√ß√£o de Stacking com K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b197afb0-58d0-42b8-8035-f1242807e467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinar_e_prever_stacking(X, y, X_test, modelos_base, meta_learner):\n",
    "    \"\"\"Implementa Stacking com K-Fold Cross-Validation\"\"\"\n",
    "    \n",
    "    kf = KFold(n_splits=KFOLD_SPLITS, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Inicializar matrizes para as previs√µes de n√≠vel 1\n",
    "    # Previs√µes de treino (out-of-fold) e previs√µes de teste (m√©dia das folds)\n",
    "    S_train = np.zeros((X.shape[0], len(modelos_base)))\n",
    "    S_test = np.zeros((X_test.shape[0], len(modelos_base)))\n",
    "    \n",
    "    # Dicion√°rio para guardar os modelos treinados em 100% dos dados\n",
    "    modelos_finais = {}\n",
    "    \n",
    "    print(f\"Iniciando Stacking com {KFOLD_SPLITS}-Fold Cross-Validation...\")\n",
    "    \n",
    "    for i, (nome, modelo) in enumerate(modelos_base.items()):\n",
    "        print(f\"\\n‚öôÔ∏è Processando Modelo Base: {nome}\")\n",
    "        \n",
    "        # 1. Gerar Previs√µes Out-of-Fold (N√≠vel 1 - Treino)\n",
    "        S_test_i = np.zeros((X_test.shape[0], kf.n_splits))\n",
    "        rmse_folds = []\n",
    "        \n",
    "        for j, (train_index, val_index) in enumerate(kf.split(X, y)):\n",
    "            X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "            \n",
    "            modelo.fit(X_train_fold, y_train_fold)\n",
    "            val_pred = modelo.predict(X_val_fold)\n",
    "            S_train[val_index, i] = val_pred\n",
    "            \n",
    "            # Previs√£o no conjunto de teste para esta fold\n",
    "            S_test_i[:, j] = modelo.predict(X_test)\n",
    "            \n",
    "            # Calcular RMSE (inverter log para m√©trica real)\n",
    "            rmse_fold = np.sqrt(mean_squared_error(np.expm1(y_val_fold), np.expm1(val_pred)))\n",
    "            rmse_folds.append(rmse_fold)\n",
    "            print(f\"   Fold {j+1} RMSE: ${rmse_fold:,.2f}\")\n",
    "            \n",
    "        S_test[:, i] = S_test_i.mean(axis=1)\n",
    "        rmse_media = np.mean(rmse_folds)\n",
    "        print(f\"   M√©dia RMSE K-Fold: ${rmse_media:,.2f}\")\n",
    "        \n",
    "        # 2. Re-treinar o modelo base em 100% dos dados (para uso futuro)\n",
    "        print(f\"   üîÑ Re-treinando {nome} em 100% dos dados...\")\n",
    "        modelo.fit(X, y)\n",
    "        modelos_finais[nome] = modelo\n",
    "        \n",
    "    # 3. Treinar Meta-Learner (N√≠vel 2)\n",
    "    print(\"\\nüèÜ Treinando Meta-Learner (Ridge) no N√≠vel 1...\")\n",
    "    meta_learner.fit(S_train, y)\n",
    "    \n",
    "    # 4. Previs√£o Final\n",
    "    final_pred_log = meta_learner.predict(S_test)\n",
    "    final_pred_reais = np.expm1(final_pred_log) # Inverter Log\n",
    "    \n",
    "    # Calcular RMSE de valida√ß√£o do Stacking (usando as previs√µes out-of-fold)\n",
    "    val_pred_stacking = meta_learner.predict(S_train)\n",
    "    rmse_stacking = np.sqrt(mean_squared_error(np.expm1(y), np.expm1(val_pred_stacking)))\n",
    "    \n",
    "    metricas_validacao = {\n",
    "        'Stacking_RMSE': rmse_stacking,\n",
    "        'Base_Model_RMSEs': {nome: np.mean(rmse_folds) for nome, modelo in modelos_base.items()}\n",
    "    }\n",
    "    \n",
    "    return final_pred_reais, modelos_finais, metricas_validacao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e765c6f0-2c46-4777-8d59-5b14334ee6f5",
   "metadata": {},
   "source": [
    "# 6. Fun√ß√µes Auxiliares (Manter a fun√ß√£o de salvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44766b71-4b34-414b-9a42-57479e8fa907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvar_submissao_log(df_sub, modelos_finais, metricas):\n",
    "    \"\"\"\n",
    "    Salva CSV e JSON incrementando o ID com base no maior n√∫mero encontrado.\n",
    "    \"\"\"\n",
    "    pasta = 'submissoes_v4'\n",
    "    os.makedirs(pasta, exist_ok=True)\n",
    "\n",
    "    # 1. Listar arquivos e encontrar o maior ID existente\n",
    "    arquivos = os.listdir(pasta)\n",
    "    ids_existentes = []\n",
    "\n",
    "    for f in arquivos:\n",
    "        if f.startswith('submission_') and f.endswith('.csv'):\n",
    "            try:\n",
    "                numero_str = f.replace('submission_', '').replace('.csv', '')\n",
    "                ids_existentes.append(int(numero_str))\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    if not ids_existentes:\n",
    "        next_id = 1\n",
    "    else:\n",
    "        next_id = max(ids_existentes) + 1\n",
    "\n",
    "    # 2. Definir nomes dos arquivos\n",
    "    filename_csv = f\"{pasta}/submission_{next_id}.csv\"\n",
    "    filename_json = f\"{pasta}/submission_{next_id}_params.json\"\n",
    "\n",
    "    # 3. Salvar CSV\n",
    "    df_sub.to_csv(filename_csv, index=False)\n",
    "\n",
    "    # 4. Metadata\n",
    "    metadata = {\n",
    "        \"id\": next_id,\n",
    "        \"modelo\": \"Stacking_XGB_GB_RF_Ridge\",\n",
    "        \"performance_validacao\": metricas,\n",
    "        \"hiperparametros_base\": {nome: modelo.get_params() for nome, modelo in modelos_finais.items()}\n",
    "    }\n",
    "\n",
    "    # 5. Salvar JSON\n",
    "    with open(filename_json, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metadata, f, indent=4, default=str)\n",
    "\n",
    "    print(f\"\\n‚úÖ Submiss√£o #{next_id} salva com sucesso!\")\n",
    "    print(f\"   üìÇ {filename_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4958089-b9ac-4282-ae06-efaf20274f90",
   "metadata": {},
   "source": [
    "# 7. Execu√ß√£o do Main (Novo Pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4958089-b9ac-4282-ae06-efaf20274f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 1. Carregar dados\n",
    "    print(\"üìÇ Carregando dados...\")\n",
    "    # ATEN√á√ÉO: Certifique-se de que os ficheiros 'dados/train.csv' e 'dados/test.csv' est√£o dispon√≠veis\n",
    "    try:\n",
    "        df_treino = pd.read_csv('dados/train.csv', index_col='id')\n",
    "        df_teste = pd.read_csv('dados/test.csv', index_col='id')\n",
    "    except FileNotFoundError:\n",
    "        print(\"ERRO: Ficheiros de dados n√£o encontrados. Certifique-se de que est√£o em 'dados/train.csv' e 'dados/test.csv'.\")\n",
    "        exit()\n",
    "\n",
    "    # 2. Prepara√ß√£o (Target Encoding e Log Target inclu√≠dos)\n",
    "    print(\"üîÑ Preparando dados com Target Encoding...\")\n",
    "    X, y_log, X_test_final, encoders = preparar_dados(df_treino, df_teste)\n",
    "\n",
    "    # 3. Definir Modelos\n",
    "    modelos_base = obter_modelos_base()\n",
    "    meta_learner = obter_meta_learner()\n",
    "\n",
    "    # 4. Treinamento e Previs√£o com Stacking e K-Fold\n",
    "    previsoes_finais, modelos_finais, metricas_validacao = treinar_e_prever_stacking(X, y_log, X_test_final, modelos_base, meta_learner)\n",
    "\n",
    "    # 5. Submiss√£o\n",
    "    print(f\"\\nüèÜ Gerando submiss√£o Stacking...\")\n",
    "    df_submissao = pd.DataFrame({\n",
    "        'id': df_teste.index,\n",
    "        'price': previsoes_finais\n",
    "    })\n",
    "\n",
    "    salvar_submissao_log(df_submissao, modelos_finais, metricas_validacao)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
